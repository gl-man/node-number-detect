

layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 1 dim: 32 dim: 320 } }
}

########################################################3
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 8
    kernel_size: 3
	pad : 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
########################################################3
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
########################################################3

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_ex/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_ex/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_ex"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
######################################
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "pool2_reshape"
  top: "pool2_reshape"
  bottom: "pool2"
  type: "Reshape"
  reshape_param {
    shape { dim: -1 }
    axis: 1
    num_axes: 2
  }
}

layer {
  name: "pool5_ave_transpose"
  top: "blstm_input"
  bottom: "pool2_reshape"
  type: "Transpose"
  transpose_param {
#	dim: 3
    dim: 2
    dim: 0
    dim: 1
  }
}

#layer {
#  name: "blstm_input"
#  type: "Reshape"
#  bottom: "pool5_ave_transpose"
#  top: "blstm_input"
#  reshape_param {
#    shape { dim: -1 }
#    axis: 1
#    num_axes: 2
#  }
#}

#===================blstm layer 1============================
#======lstm1===================
layer {
  name: "lstm1"
  type: "Lstm"
  bottom: "blstm_input"
  top: "lstm1"
  lstm_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}

# =====lstm1_reverse===================
layer {
  name: "lstm1-reverse1"
  type: "Reverse"
  bottom: "blstm_input"
  top: "rlstm1_input"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "rlstm1"
  type: "Lstm"
  bottom: "rlstm1_input"
  top: "rlstm1-output"
  lstm_param {
    num_output: 64
	weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
   }
}
layer {
  name: "lstm1-reverse2"
  type: "Reverse"
  bottom: "rlstm1-output"
  top: "rlstm1"
  reverse_param {
    axis: 0
  }
}


# merge lstm1 and rlstm1
layer {
  name: "blstm1"
  type: "Eltwise"
  bottom: "lstm1"
  bottom: "rlstm1"
  top: "blstm1"
  eltwise_param {
    operation: SUM
  }
}

#===================blstm layer 2============================

#======lstm2===================
layer {
  name: "lstm2"
  type: "Lstm"
  bottom: "blstm1"
  top: "lstm2"
  lstm_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}

# =====lstm2_reverse===================
layer {
  name: "lstm2-reverse1"
  type: "Reverse"
  bottom: "blstm1"
  top: "rlstm2_input"
  reverse_param {
    axis: 0
  }
}

layer {
  name: "rlstm2"
  type: "Lstm"
  bottom: "rlstm2_input"
  top: "rlstm2-output"
  lstm_param {
    num_output: 64
	weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
   }
}
layer {
  name: "lstm2-reverse2"
  type: "Reverse"
  bottom: "rlstm2-output"
  top: "rlstm2"
  reverse_param {
    axis: 0
  }
}

# merge lstm2 and rlstm2
layer {
  name: "blstm2"
  type: "Eltwise"
  bottom: "rlstm2"
  bottom: "lstm2"
  top: "blstm2"
  eltwise_param {
    operation: SUM
  }
}

layer {
  name: "fc1x"
  type: "InnerProduct"
  bottom: "blstm2"
  top: "fc1x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    axis: 2
    num_output: 42
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
